
# Big Picture (what interviewers actually test)

Theyâ€™re not checking if you know definitions. They want to know:

* **Latency vs reliability trade-offs**
* **Kernel/network stack behavior**
* **When TCP is a bad idea**
* **Why multicast exists**
* **How packet loss is handled in real trading systems**
* **What breaks at scale**

If you can reason about *why* things are used, youâ€™ll stand out.

---

# TCP (Transmission Control Protocol)

### Why TCP exists

* Reliable, ordered, congestion-controlled byte stream
* Guarantees **delivery**, **ordering**, **no duplication**

### How TCP works (must-know internals)

* **3-way handshake**: SYN â†’ SYN-ACK â†’ ACK
  â†’ Adds latency before first byte
* **Sequence numbers + ACKs**
* **Retransmissions**
* **Flow control** (receiver window)
* **Congestion control** (cwnd)

### TCP latency killers (HFT red flags)

| Feature               | Why itâ€™s bad                      |
| --------------------- | --------------------------------- |
| Nagleâ€™s Algorithm     | Buffers small packets             |
| Delayed ACKs          | Waits before ACK                  |
| Retransmissions       | Latency spikes                    |
| Head-of-Line Blocking | One lost packet blocks everything |
| Kernel buffering      | Adds jitter                       |

ğŸ‘‰ **HFT fix**:

```cpp
setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, ...)
```

### Why TCP is still used in HFT

* **Order entry**
* **Risk management**
* **Trade confirmations**

Because:

* Losing an order is worse than being slow
* Exchanges often **require TCP**

### Interview killer line

> â€œTCP optimizes for throughput and fairness, not tail latency. In HFT, tail latency is often more important than average latency.â€

---

# UDP (User Datagram Protocol)

### What UDP really is

* No connection
* No ordering
* No retransmission
* No congestion control
* Message-oriented (datagrams)

### Why HFT loves UDP

* **Lowest possible latency**
* No head-of-line blocking
* No kernel retries
* One packet = one message

### The dark side of UDP

| Problem         | Impact             |
| --------------- | ------------------ |
| Packet loss     | You must handle it |
| Reordering      | Happens at scale   |
| Duplication     | Rare but real      |
| No backpressure | Receiver can drop  |

### How HFT systems handle UDP loss

* **Sequence numbers in payload**
* **Gap detection**
* **Request retransmit via TCP**
* **Snapshot + incremental feed**

> Market data feeds almost always combine **UDP multicast + TCP recovery**

### Interview killer line

> â€œUDP trades correctness for determinism. In trading, we prefer knowing *now* that data is missing rather than finding out later.â€

---

# Multicast (the secret sauce)

### What multicast is

* One sender â†’ many receivers
* Implemented using **UDP**
* Network replicates packets (not sender)

### Why exchanges use multicast

* Market data fan-out
* Same packet, same time, same latency
* Fair dissemination

### Multicast vs Unicast UDP

|            | Multicast | Unicast   |
| ---------- | --------- | --------- |
| Bandwidth  | Efficient | Expensive |
| Fairness   | High      | Low       |
| Complexity | Higher    | Lower     |

### Multicast gotchas (very interviewable)

* **Packet loss is normal**
* **No built-in recovery**
* **Receiver joins late â†’ misses data**
* **NIC / switch buffer overruns**

### Real HFT multicast architecture

```
[Exchange]
   |
UDP Multicast
   |
[Feed Handler]
   |
TCP Snapshot / Recovery
   |
Order Book Builder
```

### Interview killer line

> â€œMulticast gives fairness but not reliability. Reliability is added *at the application layer*, not the transport layer.â€

---

# Kernel & OS Stuff (this is where senior candidates win)

### Socket buffers

```bash
net.core.rmem_max
net.core.wmem_max
```

* Too small â†’ drops
* Too big â†’ cache misses

### Busy polling / kernel bypass

* `SO_BUSY_POLL`
* DPDK / Solarflare Onload / Mellanox VMA
* User-space networking

> Expect questions like: *â€œHow do you reduce kernel jitter?â€*

### NUMA awareness

* NIC IRQ affinity
* Thread pinning
* Memory locality

### Timestamping

* HW vs SW timestamps
* PTP (Precision Time Protocol)

---

# TCP vs UDP vs Multicast (HFT summary table)

| Use case       | Protocol      | Why                 |
| -------------- | ------------- | ------------------- |
| Market data    | UDP Multicast | Fan-out + fairness  |
| Order entry    | TCP           | Reliability         |
| Recovery       | TCP           | Guaranteed delivery |
| Internal feeds | UDP           | Low latency         |
| Risk checks    | TCP           | Correctness > speed |

---

# Common Interview Traps âš ï¸

**Q:** Why not use TCP for market data?
**A:** Head-of-line blocking and retransmissions cause unpredictable latency spikes.

**Q:** Why not use UDP for orders?
**A:** Losing an order is catastrophic; retransmissions must be reliable.

**Q:** What happens if multicast packet is lost?
**A:** Detect via sequence numbers â†’ request snapshot or gap fill via TCP.

**Q:** How do exchanges ensure fairness?
**A:** Multicast + deterministic packet timing.

---

# One-Liners You Can Drop Casually ğŸ’£

* â€œTail latency matters more than mean latency in trading.â€
* â€œTCP is optimized for throughput, not determinism.â€
* â€œMulticast gives fairness; TCP gives correctness.â€
* â€œWe handle packet loss explicitly instead of hiding it.â€

---

# TCP Handshake (in real detail)

TCP is **stateful**. Before any data flows, both sides must agree on:

* Sequence numbers
* Window sizes
* Capabilities (timestamps, SACK, etc.)

## 1ï¸âƒ£ Three-Way Handshake

### Step 1: SYN

Client â†’ Server

```
SYN, seq = x
```

Client says:

> â€œI want to talk, and Iâ€™ll start counting bytes from x.â€

Whatâ€™s happening internally:

* Socket moves from `CLOSED` â†’ `SYN_SENT`
* Initial Sequence Number (ISN) chosen (randomized for security)
* TCP options sent:

  * MSS
  * Window Scale
  * SACK permitted
  * Timestamps (optional)

---

### Step 2: SYN-ACK

Server â†’ Client

```
SYN, ACK = x+1, seq = y
```

Server says:

> â€œI heard you. Iâ€™ll start at y, and I expect x+1 next.â€

Internals:

* Server allocates **connection state**
* Moves socket to `SYN_RECEIVED`
* Half-open connection exists

âš ï¸ **SYN flood vulnerability** lives here.

---

### Step 3: ACK

Client â†’ Server

```
ACK = y+1
```

Client says:

> â€œWeâ€™re synced. Letâ€™s send data.â€

Both sides:

* Move to `ESTABLISHED`
* Data can now flow

---

## ğŸ”¥ Why this handshake hurts in HFT

### Latency cost

* Minimum **1 RTT before first byte**
* Worse over WAN or congested networks

### State cost

* Kernel allocates buffers
* TCP control blocks created
* Cache pollution

### Failure impact

* If SYN or SYN-ACK is dropped â†’ handshake retries
* Adds jitter and long tail latency

---

## TCP Fast Open (TFO)

Some systems allow:

```
SYN + DATA
```

But:

* Not universally supported
* Still stateful
* Rare in exchange connectivity

ğŸ‘‰ Donâ€™t oversell TFO in interviews.

---

# TCP Teardown (often overlooked)

Connection close also has a handshake:

```
FIN â†’ ACK â†’ FIN â†’ ACK
```

Problems:

* `TIME_WAIT`
* Port exhaustion
* Delays reconnects

ğŸ’¡ HFT systems:

* Keep TCP connections **long-lived**
* Avoid reconnects during trading hours

---

# UDP â€œHandshakeâ€ (or lack thereof)

### Key point

ğŸ‘‰ **UDP has no handshake at transport layer**

You can send data immediately:

```
sendto()
```

No:

* SYN
* ACK
* State
* RTT wait

### What UDP really does

* Wraps payload in IP packet
* Best-effort delivery

Thatâ€™s it.

---

## Butâ€¦ HFT Still Adds â€œHandshakesâ€ on top of UDP

Interviewers LOVE this nuance.

### Application-level handshake (common pattern)

Example:

```
Client â†’ Server: LOGIN (seq=0)
Server â†’ Client: LOGIN_ACK
Client â†’ Server: SUBSCRIBE_FEED
```

Why?

* Identity
* Permissions
* Sequence alignment
* Recovery starting point

This is **not UDP doing it**, but the **application protocol**.

---

# Multicast Handshake (IGMP)

Multicast does have a *network-level* handshake:

### IGMP Join

Receiver â†’ Network

```
IGMP JOIN group 239.x.x.x
```

Switch/router:

* Starts forwarding multicast traffic

But:

* Sender is unaware
* No reliability
* No confirmation

ğŸ’¡ This is why:

> â€œJoining late means missing data forever unless recovery exists.â€

---

# Comparing Handshakes (Interview Table)

| Protocol  | Handshake | State     | RTT Cost | Reliability |
| --------- | --------- | --------- | -------- | ----------- |
| TCP       | 3-way     | Yes       | â‰¥1 RTT   | Built-in    |
| UDP       | None      | No        | 0        | None        |
| UDP + App | Custom    | App-level | Optional | App-defined |
| Multicast | IGMP      | Network   | Minimal  | None        |

---

# Packet Loss During Handshake (Great Interview Angle)

### TCP

* SYN lost â†’ retransmit
* SYN-ACK lost â†’ retransmit
* Exponential backoff
* Latency spike

### UDP

* No retries
* App must detect silence
* Timeouts are **explicit**

ğŸ‘‰ HFT prefers **knowing immediately** that something failed.

---

# One-Liners to Drop ğŸ’£

* â€œTCP handshake establishes shared state; UDP avoids shared state entirely.â€
* â€œUDP removes the RTT tax.â€
* â€œMulticast handshakes are about group membership, not reliability.â€
* â€œHFT systems shift reliability from transport to application layer.â€

---

# Common Follow-Up Questions They May Ask

* Can TCP send data before handshake completes?
* How does SYN flood affect latency?
* Why is TIME_WAIT a problem?
* How do you resync a UDP feed?
* What happens if IGMP join is slow?
